{
  "llama_cloud_config": {
    "ionos_token_file": "ionos_token.txt",
    "cloud_model_name": "meta-llama/Meta-Llama-3.1-70B-Instruct",
    "cloud_model_name1": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "endpoint": "https://openai.inference.de-txl.ionos.com/v1/chat/completions",
    "role_file": "prompt_cloud.txt"
  },
  "llama_model": {
    "directory": "/home/radwan/Desktop/startUp_stuff/llama",
    "file1": "Llama-3.2-3B-Instruct-Q6_K_L.gguf",
    "file": "Meta-Llama-3.1-8B-Instruct-Q6_K_L.gguf",
    "n_gpu_layers": 15,
    "n_ctx": 2048,
    "n_threads": -1,
    "use_mlock": true,
    "role_file": "prompt.txt"
  },

  "whisper_model": {
    "name": "turbo",
    "device": "cuda"
  },
  "piper": {
    "url": "http://localhost:5000"
  },
  "audio": {
    "format": "paInt16",
    "channels": 1,
    "rate": 16000,
    "frame_duration_ms": 30,
    "silence_threshold_sec": 1
  },
  "use_cloud": false,
  "system_role": "Du bist ein hilfreicher Assistent",

  "initial_message": "Hallo und Willkommen. Hier ist Jan. Was kann ich f√ºr Sie tun?"
}